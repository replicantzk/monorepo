---
title: TLDR
---

# TLDR

## Do you want a low-cost LLM API?

Our API is OpenAI-compatible with streaming suppport and can be used with the OpenAI client libraries. Try the network with our chat demo [here](https://huggingface.co/spaces/mvkvc/replicant_chat) to see it in action. Credits are not yet outright purchasable and so you will need to sign up as a worker to earn credits for the API. Once released the prices will be lower than centralized services with sustainable pricing ex. Replicate.

## Do you want to put your GPU to work for you?

Install [Ollama](https://ollama.com/download) and our desktop app to earn credits for leaving your PC GPU running. We encourage to run the largest model your GPU memory allows as you earn credits relative to model size. In order to mitigate abuse we currently request a minimum amount of credits to participate which can be requested in the Discord server (see header). All our code including the app is open-source so you can verify what is being run on your computer. We try to only enable the minimum local permissions necessary for the app to work, which you can see [here](https://github.com/replicantzk/monorepo/blob/main/apps/worker_app/src-tauri/tauri.conf.json). If you have any questions or concerns please let us know in the Discord server (see header).
